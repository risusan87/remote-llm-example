# remote-llm-example
Proposes one of many ways to bridge backend logic and cloud GPUs so your application can benefit from power of LLM.

To test this, you want to have a confident way to request and view http requests. For me personally use Postman.

## Setting up
1. Python version is 3.10+. Virtual environment with venv is recommended. 
2. You will need Modal account. Create an account and follow their instruction to activate for your env.

## Running

